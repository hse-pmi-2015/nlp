{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.parsing.preprocessing import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "df_corpus = pd.read_csv('corpus.csv',index_col=0)\n",
    "\n",
    "corpus = []\n",
    "for topic in df_corpus:\n",
    "    corpus += df_corpus[topic].tolist()\n",
    "\n",
    "answ_corpus = pd.Series(corpus)\n",
    "answ_corpus = answ_corpus.apply(strip_tags)\n",
    "answ_corpus = answ_corpus.apply(strip_multiple_whitespaces)\n",
    "corpus = pd.Series(corpus)\n",
    "corpus = corpus.apply(lambda x: x.lower())\n",
    "corpus = corpus.apply(strip_tags)\n",
    "corpus = corpus.apply(strip_punctuation2)\n",
    "corpus = corpus.apply(strip_numeric)\n",
    "corpus = corpus.apply(lambda x: re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', u' ', x))\n",
    "corpus = corpus.apply(lambda x: re.sub('«|»', ' ', x))\n",
    "corpus = corpus.apply(strip_multiple_whitespaces)\n",
    "\n",
    "\n",
    "\n",
    "import stop_words\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "corpus_tokens = []\n",
    "inds_to_drop = []\n",
    "\n",
    "for i, sentence in enumerate(corpus[:]):\n",
    "    tmp_tokens = []\n",
    "    sp = sentence.split()\n",
    "    for word in sp:\n",
    "        if word not in stop_words.get_stop_words('ru'):\n",
    "            if morph.word_is_known(word):\n",
    "                tmp_tokens.append(word)\n",
    "    if len(tmp_tokens) > 0:\n",
    "        corpus_tokens.append(tmp_tokens)\n",
    "    else:\n",
    "        inds_to_drop.append(i)\n",
    "        \n",
    "print(len(corpus_tokens))\n",
    "\n",
    "\n",
    "stemmer = RussianStemmer()\n",
    "\n",
    "corpus_tokens_stem = []\n",
    "\n",
    "for i, tokens in enumerate((corpus_tokens[:])):\n",
    "    tmp = [stemmer.stem(word) for word in tokens]\n",
    "    corpus_tokens_stem.append(tmp)\n",
    "    \n",
    "print(len(corpus_tokens_stem))\n",
    "\n",
    "\n",
    "clear_corpus = []\n",
    "for token_list in corpus_tokens_stem:\n",
    "    if len(' '.join(token_list))<2:\n",
    "        print(token_list)\n",
    "    clear_corpus.append(' '.join(token_list))\n",
    "clear_corpus[0]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(clear_corpus)\n",
    "X = vectorizer.transform(clear_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 4\n",
    "max_iteration = 100\n",
    "batch_size = 15\n",
    "evaluate_every=1\n",
    "verb=1\n",
    "learning_method='batch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=N_TOPICS, max_iter=max_iteration, batch_size=batch_size, evaluate_every=evaluate_every, verbose=verb, \n",
    "                                        n_jobs=4, learning_method=learning_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 100, perplexity: 27600.9063\n",
      "iteration: 2 of max_iter: 100, perplexity: 25580.9740\n",
      "iteration: 3 of max_iter: 100, perplexity: 23735.5510\n",
      "iteration: 4 of max_iter: 100, perplexity: 21765.0470\n",
      "iteration: 5 of max_iter: 100, perplexity: 19935.3627\n",
      "iteration: 6 of max_iter: 100, perplexity: 18475.8418\n",
      "iteration: 7 of max_iter: 100, perplexity: 17352.7465\n",
      "iteration: 8 of max_iter: 100, perplexity: 16622.6509\n",
      "iteration: 9 of max_iter: 100, perplexity: 16238.9430\n",
      "iteration: 10 of max_iter: 100, perplexity: 15970.6553\n",
      "iteration: 11 of max_iter: 100, perplexity: 15741.7401\n",
      "iteration: 12 of max_iter: 100, perplexity: 15616.6990\n",
      "iteration: 13 of max_iter: 100, perplexity: 15549.1735\n",
      "iteration: 14 of max_iter: 100, perplexity: 15530.5198\n",
      "iteration: 15 of max_iter: 100, perplexity: 15507.7614\n",
      "iteration: 16 of max_iter: 100, perplexity: 15490.3553\n",
      "iteration: 17 of max_iter: 100, perplexity: 15476.5739\n",
      "iteration: 18 of max_iter: 100, perplexity: 15448.1999\n",
      "iteration: 19 of max_iter: 100, perplexity: 15425.6135\n",
      "iteration: 20 of max_iter: 100, perplexity: 15398.7394\n",
      "iteration: 21 of max_iter: 100, perplexity: 15383.4134\n",
      "iteration: 22 of max_iter: 100, perplexity: 15376.7798\n",
      "iteration: 23 of max_iter: 100, perplexity: 15368.7662\n",
      "iteration: 24 of max_iter: 100, perplexity: 15367.8163\n",
      "iteration: 25 of max_iter: 100, perplexity: 15366.0117\n",
      "iteration: 26 of max_iter: 100, perplexity: 15363.4670\n",
      "iteration: 27 of max_iter: 100, perplexity: 15362.7890\n",
      "iteration: 28 of max_iter: 100, perplexity: 15362.2383\n",
      "iteration: 29 of max_iter: 100, perplexity: 15361.8557\n",
      "iteration: 30 of max_iter: 100, perplexity: 15361.5690\n",
      "iteration: 31 of max_iter: 100, perplexity: 15361.3385\n",
      "iteration: 32 of max_iter: 100, perplexity: 15361.1346\n",
      "iteration: 33 of max_iter: 100, perplexity: 15360.9456\n",
      "iteration: 34 of max_iter: 100, perplexity: 15360.7670\n",
      "iteration: 35 of max_iter: 100, perplexity: 15360.5979\n",
      "iteration: 36 of max_iter: 100, perplexity: 15360.4390\n",
      "iteration: 37 of max_iter: 100, perplexity: 15360.2790\n",
      "iteration: 38 of max_iter: 100, perplexity: 15360.0461\n",
      "iteration: 39 of max_iter: 100, perplexity: 15359.1011\n",
      "iteration: 40 of max_iter: 100, perplexity: 15357.5075\n",
      "iteration: 41 of max_iter: 100, perplexity: 15357.1431\n",
      "iteration: 42 of max_iter: 100, perplexity: 15356.8481\n",
      "iteration: 43 of max_iter: 100, perplexity: 15356.3951\n",
      "iteration: 44 of max_iter: 100, perplexity: 15354.4891\n",
      "iteration: 45 of max_iter: 100, perplexity: 15349.5526\n",
      "iteration: 46 of max_iter: 100, perplexity: 15348.1379\n",
      "iteration: 47 of max_iter: 100, perplexity: 15347.6236\n",
      "iteration: 48 of max_iter: 100, perplexity: 15346.9942\n",
      "iteration: 49 of max_iter: 100, perplexity: 15346.3156\n",
      "iteration: 50 of max_iter: 100, perplexity: 15345.5650\n",
      "iteration: 51 of max_iter: 100, perplexity: 15344.4621\n",
      "iteration: 52 of max_iter: 100, perplexity: 15341.6033\n",
      "iteration: 53 of max_iter: 100, perplexity: 15336.5298\n",
      "iteration: 54 of max_iter: 100, perplexity: 15329.9192\n",
      "iteration: 55 of max_iter: 100, perplexity: 15326.2046\n",
      "iteration: 56 of max_iter: 100, perplexity: 15320.4313\n",
      "iteration: 57 of max_iter: 100, perplexity: 15308.2494\n",
      "iteration: 58 of max_iter: 100, perplexity: 15295.5711\n",
      "iteration: 59 of max_iter: 100, perplexity: 15284.8797\n",
      "iteration: 60 of max_iter: 100, perplexity: 15276.4247\n",
      "iteration: 61 of max_iter: 100, perplexity: 15268.2403\n",
      "iteration: 62 of max_iter: 100, perplexity: 15262.5054\n",
      "iteration: 63 of max_iter: 100, perplexity: 15258.0103\n",
      "iteration: 64 of max_iter: 100, perplexity: 15257.5752\n",
      "iteration: 65 of max_iter: 100, perplexity: 15256.4836\n",
      "iteration: 66 of max_iter: 100, perplexity: 15253.7730\n",
      "iteration: 67 of max_iter: 100, perplexity: 15253.4054\n",
      "iteration: 68 of max_iter: 100, perplexity: 15251.3197\n",
      "iteration: 69 of max_iter: 100, perplexity: 15249.9568\n",
      "iteration: 70 of max_iter: 100, perplexity: 15249.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=15, doc_topic_prior=None,\n",
       "             evaluate_every=1, learning_decay=0.7, learning_method='batch',\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=100,\n",
       "             mean_change_tol=0.001, n_components=4, n_jobs=4,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "svd = TruncatedSVD(n_components=N_TOPICS, n_iter=100).fit(X)\n",
    "\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8757 8757 8757\n"
     ]
    }
   ],
   "source": [
    "keys = list(vectorizer.vocabulary_.keys())\n",
    "values = list(vectorizer.vocabulary_.values())\n",
    "\n",
    "_ind = np.argsort(values)\n",
    "words_sorted = np.asarray(keys)[_ind]\n",
    "\n",
    "print(len(keys), len(values), len(words_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['14', '3', '5', '7'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10326071 0.10963394 0.11180692 0.11761075 0.11883023 0.13811186\n",
      " 0.1778697  0.18489953 0.19264438]\n",
      "['прощан' 'войн' 'стар' 'артист' 'приключен' 'вахтангов' 'актер' 'театр'\n",
      " 'этуш']\n",
      "\n",
      "[0.10341654 0.10780936 0.12882586 0.20553013 0.20749934]\n",
      "['кровел' 'ямочн' 'вывезл' 'автовышк' 'куб']\n",
      "\n",
      "[0.10743302 0.10854844 0.12337026 0.12765806 0.15341745 0.16029703\n",
      " 0.20743902 0.34525624]\n",
      "['московск' 'компан' 'пресс' 'росс' 'руб' 'служб' 'тыс' 'москв']\n",
      "\n",
      "[0.10356885 0.10890642 0.1114912  0.11399445 0.13236054 0.14288891\n",
      " 0.1660668  0.1968348  0.27397104 0.34109378]\n",
      "['опроверг' 'беремен' 'неправд' 'шутк' 'тянет' 'нейрохирург' 'враг'\n",
      " 'распуст' 'спин' 'назар']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "stub = [0] * N_TOPICS\n",
    "threshold = 0.1\n",
    "\n",
    "for i in range(N_TOPICS):\n",
    "    \n",
    "    szd = pd.Series(np.sort(svd.components_[i])[-10:])\n",
    "    szd_mask = szd.apply(lambda x: False if x<threshold else True)\n",
    "    \n",
    "    print(szd[szd_mask].values)\n",
    "    \n",
    "    ind = np.argsort(lda.components_[i])[-szd[szd_mask].shape[0]:]\n",
    "    print(words_sorted[ind])\n",
    "    \n",
    "    print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# политика # экономика # технологии # общество "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
